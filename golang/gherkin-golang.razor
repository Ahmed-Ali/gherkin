@using Berp;
@helper CallProduction(ProductionRule production)
{
  switch(production.Type)
  {
    case ProductionRuleType.Start:
      @:ctxt.startRule(@Raw("RuleType_" + production.RuleName.Replace("#", "_")));
      break;
    case ProductionRuleType.End:
      @:ctxt.endRule(@Raw("RuleType_" + production.RuleName.Replace("#", "_")));
      break;
    case ProductionRuleType.Process:
      @:ctxt.build(token);
      break;
  }
}
@helper HandleParserError(IEnumerable<string> expectedTokens, State state)
{<text>
    // var stateComment = "State: @state.Id - @Raw(state.Comment)"
    var expectedTokens = []string{"@Raw(string.Join("\", \"", expectedTokens))"}
    if line.IsEof() {
      err = fmt.Errorf("(%d:0): unexpected end of file, expected: %s", line.lineNumber, strings.Join(expectedTokens,", "))
    } else {
      err = fmt.Errorf("(%d:0): expected: %s, got '%s'",line.lineNumber, strings.Join(expectedTokens,", "), line.lineText,
      )
    }
    // if (ctxt.p.stopAtFirstError) throw error;
    //ctxt.addError(err)
    return err, @state.Id</text>}
@helper MatchToken(TokenType tokenType)
{<text>ctxt.match_@(tokenType)(line)</text>}
@helper IsMatchToken(TokenType tokenType)
{<text>ctxt.isMatch_@(tokenType)(line)</text>}
@helper TokenConst(Rule rule)
{<text>@Raw("rule" + rule.Name.Replace("#", "Int"))</text>}
// 
// This file is generated. Do not edit! Edit gherkin-golang.razor instead.

// 
package gherkin3;

import (
  "fmt"
  "strings"
)

type TokenType int

const (
  TokenType_None TokenType = iota
  @foreach(var rule in Model.RuleSet.TokenRules)
  {<text>  @Raw("TokenType_" + rule.Name.Replace("#", ""))
</text>}
)

func tokenTypeForRule(rt RuleType) TokenType {
    return TokenType_None
}

func (t TokenType) Name() string {
  switch t {
  @foreach(var rule in Model.RuleSet.TokenRules)
  {<text>    case @Raw("TokenType_" + rule.Name.Replace("#", "")): return "@Raw(rule.Name.Replace("#", ""))"
</text>}
  }
  return ""
}

func (t TokenType) RuleType() RuleType {
  switch t {
  @foreach(var rule in Model.RuleSet.TokenRules)
  {<text>    case @Raw("TokenType_" + rule.Name.Replace("#", "")): return @Raw("RuleType_" + rule.Name.Replace("#", "_"))
</text>}
  }
  return RuleType_None
}


type RuleType int

const (
  RuleType_None RuleType = iota 

  @foreach(var rule in Model.RuleSet.Where(r => !r.TempRule))
  {<text>  @Raw("RuleType_" + rule.Name.Replace("#", "_"))
</text>}
)

func (t RuleType) IsEOF() bool {
  return t == RuleType__EOF
}
func (t RuleType) Name() string {
  switch t {
  @foreach(var rule in Model.RuleSet.Where(r => !r.TempRule))
    {<text>    case @Raw("RuleType_" + rule.Name.Replace("#", "_")): return "@Raw(rule.Name)"
</text>}
  }
  return ""
}

type parseError struct {
  msg  string
  loc *Location
}

func (a *parseError) Error() string {
  return fmt.Sprintf("(%d:%d): %s", a.loc.Line, a.loc.Column, a.msg)
}

type parseErrors []error
func (pe parseErrors) Error() string {
  var ret = []string{"Parser errors:"}
  for i := range pe {
    ret = append(ret, pe[i].Error())
  }
  return strings.Join(ret,"\n")
}

func (p *parser) Parse(s Scanner, b Builder, m Matcher) (err error) {
  ctxt := &parseContext{p,s,b,m,nil,nil}
  var state int
  ctxt.startRule(RuleType_Feature)
  for {
    err, gl, eof := ctxt.scan()
    if err != nil {
      ctxt.addError(err)
      if p.stopAtFirstError {
        break
      }
    }
    err, state = ctxt.match(state, gl)
    if err != nil {
      ctxt.addError(err)
      if p.stopAtFirstError {
        break
      }
    }
    if eof {
      // done! \o/
      break
    }
  }
  ctxt.endRule(RuleType_Feature)
  if len(ctxt.errors) > 0 {
    return ctxt.errors
  }
  return
}

type parseContext struct {
  p      *parser
  s      Scanner
  b      Builder
  m      Matcher
  queue  []*scanResult
  errors parseErrors
}

func (ctxt *parseContext) addError(e error) {
  ctxt.errors = append(ctxt.errors, e);
  // if (p.errors.length > 10)
  //   throw Errors.CompositeParserException.create(p.errors);
}

type scanResult struct {
  err   error
  line  *Line
  atEof bool
}
func (ctxt *parseContext) scan() (error, *Line, bool) {
  l := len(ctxt.queue)
  if l > 0 {
    x := ctxt.queue[0]
    ctxt.queue = ctxt.queue[1:]
    return x.err, x.line, x.atEof
  }
  return ctxt.s.Scan()
}

func (ctxt *parseContext) startRule(r RuleType) (error, bool) {
  err, ok := ctxt.b.StartRule(r)
  if err != nil {
    ctxt.addError(err)
  }
  return err, ok
}

func (ctxt *parseContext) endRule(r RuleType) (error, bool) {
  err, ok := ctxt.b.EndRule(r)
  if err != nil {
    ctxt.addError(err)
  }
  return err, ok
}

func (ctxt *parseContext) build(t *Token) (error, bool) {
  err, ok := ctxt.b.Build(t)
  if err != nil {
    ctxt.addError(err)
  }
  return err, ok
}


func (ctxt *parseContext) match(state int, line *Line) (err error, newState int) {
  switch(state) {
  @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
  {
  @:case @state.Id:
    @:return ctxt.matchAt_@(state.Id)(line);
  }
  default:
    return fmt.Errorf("Unknown state: %+v", state), state;
  }
  return nil, state
}

@foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
{
<text>
  // @Raw(state.Comment)
func (ctxt *parseContext) matchAt_@(state.Id)(line *Line) (err error, newState int) {
  @foreach(var transition in state.Transitions)
  {
  @:if err, ok, token := @MatchToken(transition.TokenType); ok {
    if (transition.LookAheadHint != null)
    {
    @:if ctxt.lookahead_@(transition.LookAheadHint.Id)(line) {
    }
    foreach(var production in transition.Productions)
    {
      @CallProduction(production)
    }
    @:return err, @transition.TargetState;
    if (transition.LookAheadHint != null)
    {
    @:}
    }
  @:}
  }
  @HandleParserError(state.Transitions.Select(t => "#" + t.TokenType.ToString()).Distinct(), state)
}
</text>
}

type Matcher interface {
  @foreach(var rule in Model.RuleSet.TokenRules)
  {<text>  Match@(rule.Name.Replace("#", ""))(line *Line) (error,bool,*Token)
</text>}  
}
@foreach(var rule in Model.RuleSet.TokenRules)
{
<text>
func (ctxt *parseContext) isMatch_@(rule.Name.Replace("#", ""))(line *Line) bool {
  _, ok, _ := ctxt.match_@(rule.Name.Replace("#", ""))(line)
  return ok
}
func (ctxt *parseContext) match_@(rule.Name.Replace("#", ""))(line *Line) (error, bool, *Token) {
    @if (rule.Name != "#EOF")
    {
    @:if line.IsEof() {
    @:  return nil, false, nil
    @:}
    }
    return ctxt.m.Match@(rule.Name.Replace("#", ""))(line);
}
</text>
}

@foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
{
<text>
func (ctxt *parseContext) lookahead_@(lookAheadHint.Id)(initialLine *Line) bool {
    var queue []*scanResult
    var match bool

    for {
      err, line, atEof := ctxt.scan();
      queue = append(queue, &scanResult{err,line,atEof});

      if false @foreach(var tokenType in lookAheadHint.ExpectedTokens) { <text>|| @IsMatchToken(tokenType)</text>} {
        match = true;
        break
      }
      if false @foreach(var tokenType in lookAheadHint.Skip) { <text>|| @IsMatchToken(tokenType)</text>} {
        break
      }
      if atEof {
        break
      }
    }

    ctxt.queue = append(ctxt.queue, queue...)

    return match;
  }
</text>
}

/*
  function handleExternalError(context, defaultValue, action) {
    if(this.stopAtFirstError) return action();
    try {
      return action();
    } catch (e) {
      if(e instanceof Errors.CompositeParserException) {
        e.errors.forEach(function (error) {
          addError(context, error);
        });
      } else if(
        e instanceof Errors.ParserException ||
        e instanceof Errors.AstBuilderException ||
        e instanceof Errors.UnexpectedTokenException ||
        e instanceof Errors.NoSuchLanguageException
      ) {
        addError(context, e);
      } else {
        throw e;
      }
    }
    return defaultValue;
  }

@foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
{
<text>
  function lookahead_@(lookAheadHint.Id)(context, currentToken) {
    currentToken.detach();
    var token;
    var queue = [];
    var match = false;
    do {
      token = readToken(context);
      token.detach();
      queue.push(token);

      if (false @foreach(var tokenType in lookAheadHint.ExpectedTokens) { <text>|| @IsMatchToken(tokenType)</text>}) {
        match = true;
        break;
      }
    } while(false @foreach(var tokenType in lookAheadHint.Skip) { <text>|| @IsMatchToken(tokenType)</text>});

    context.tokenQueue = context.tokenQueue.concat(queue);

    return match;
  }
</text>
}

}
*/